{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as backend \n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input, BatchNormalization, Reshape, UpSampling2D,LeakyReLU,concatenate, Lambda, Concatenate, ReLU,ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedings(embeding_filepath):\n",
    "    with open(embeding_filepath,\"rb\") as f:\n",
    "        embedings = pickle.load(f,encoding=\"latin\")\n",
    "        \n",
    "    a_embeding = np.array(embedings)\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in range(a_embeding.shape[0]):\n",
    "        a1_embeding = a_embeding[i,:,:]\n",
    "        ix = np.random.randint(0, a1_embeding.shape[0]-1)\n",
    "        embedding = a1_embeding[ix,:]\n",
    "        \n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "def load_images(images_path):\n",
    "    with open(images_path,\"rb\") as f:\n",
    "        images = pickle.load(f)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def ca_model(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = backend.exp(log_sigma)\n",
    "    epsilon = backend.random_normal(shape=backend.constant((mean.shape[1],), dtype='int32'))\n",
    "    c = stddev * epsilon + mean\n",
    "    return c\n",
    "\n",
    "def Compressed_embed():\n",
    "    input_layer = Input((1024,))\n",
    "    \n",
    "    x = Dense(128)(input_layer)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model\n",
    "\n",
    "def Combined_model(g_model, d_model):\n",
    "    input_layer = Input((1024,))\n",
    "    input_layer2 = Input((100,))\n",
    "    input_layer3 = Input((4,4,128))\n",
    "    \n",
    "    x, mean_logsigma = g_model([input_layer, input_layer2])\n",
    "    d_model.trainable = False\n",
    "    v = d_model([x, input_layer3])\n",
    "    \n",
    "    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[v, mean_logsigma])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    input_layer = Input((1024,))\n",
    "    \n",
    "    x = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    c = Lambda(ca_model)(mean_logsigma)\n",
    "    \n",
    "    input_layer2 = Input((100,))\n",
    "    \n",
    "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
    "\n",
    "    x = Dense(4*4*128*8, use_bias=False)(gen_input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Reshape((4,4,128*8), input_shape=(128*8*4*4,))(x)\n",
    "    x = UpSampling2D((2, 2), data_format=\"channels_last\")(x)\n",
    "    x = Conv2D(512,kernel_size=3,padding='same', data_format=\"channels_last\", kernel_initializer='he_normal')(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2D(128,kernel_size=3,padding='same', data_format=\"channels_last\", kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2D(64,kernel_size=3,padding='same', data_format=\"channels_last\", kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2D(3,kernel_size=3,padding='same', data_format=\"channels_last\", kernel_initializer='he_normal')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_layer,input_layer2], outputs=[x, mean_logsigma])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    input_layer1 = Input((64,64,3))\n",
    "    x = Conv2D(64,kernel_size=(4,4),\n",
    "                            strides=(2,2),\n",
    "                            padding='same',\n",
    "                            data_format=\"channels_last\",\n",
    "                            input_shape=(64,64,3),\n",
    "                            use_bias=False\n",
    "                            )(input_layer1)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(128, kernel_size=(4,4), padding=\"same\",strides=(2,2), data_format=\"channels_last\",kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=(4,4), padding=\"same\",strides=(2,2), data_format=\"channels_last\",kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(512, kernel_size=(4,4), padding=\"same\",strides=(2,2), data_format=\"channels_last\",kernel_initializer='he_normal')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    input_layer2 = Input((4,4,128))\n",
    "    marge_input = concatenate([x, input_layer2],)\n",
    "    \n",
    "    x2 = Conv2D(128, kernel_size=(4,4), padding=\"same\",strides=(2,2), data_format=\"channels_last\",kernel_initializer='he_normal')(marge_input)\n",
    "    x2 = LeakyReLU(0.2)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(1)(x2)\n",
    "    x2 = Activation('sigmoid')(x2)\n",
    "    \n",
    "    model = Model(inputs=[input_layer1, input_layer2], outputs=[x2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_block(inputs):\n",
    "    c = inputs[0]\n",
    "    x = inputs[1]\n",
    "\n",
    "    c = tf.expand_dims(c, axis=1)\n",
    "    c = tf.expand_dims(c, axis=1)\n",
    "    c = tf.tile(c, [1, 16, 16, 1])\n",
    "    \n",
    "    con = tf.concat([c,x], 3)#([c,x],axis=3)\n",
    "    return con\n",
    "\n",
    "def residual_block(input):\n",
    "    \"\"\"\n",
    "    Residual block in the generator network\n",
    "    \"\"\"\n",
    "    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = add([x, input])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def KL_loss(y_true, y_pred):\n",
    "    mean = y_pred[:, :128]\n",
    "    logsigma = y_pred[:, :128]\n",
    "    loss = -logsigma + .5 * (-1 + backend.exp(2. * logsigma) + backend.square(mean))\n",
    "    loss = backend.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator2():\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    input_images = Input(shape=(64,64,3))\n",
    "    \n",
    "    ca = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n",
    "    c = Lambda(ca_model)(mean_logsigma)\n",
    "    \n",
    "    x = ZeroPadding2D(padding=(1,1))(input_images)\n",
    "    x = Conv2D(128, kernel_size=(3,3), strides=1, use_bias=False)(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    print(x)\n",
    "    c_comb = Lambda(joint_block)([c,x])\n",
    "    \n",
    "    x = ZeroPadding2D(padding=(1, 1))(c_comb)\n",
    "    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_layer, input_images], outputs=[x, mean_logsigma])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator2():\n",
    "    input_layer = Input((256,256,3))\n",
    "    \n",
    "    x = Conv2D(64,(4,4), padding='same', strides=2, input_shape=(256,256,3),use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "\n",
    "    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "\n",
    "    x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n",
    "    x2 = BatchNormalization()(x2) \n",
    "    \n",
    "    added_x = add([x,x2])\n",
    "    added_x = LeakyReLU(alpha=0.2)(added_x)\n",
    "\n",
    "    input_layer2 = Input(shape=(4, 4, 128))\n",
    "    \n",
    "    merged_input = concatenate([added_x, input_layer2])\n",
    "\n",
    "    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.2)(x3)\n",
    "    x3 = Flatten()(x3)\n",
    "    x3 = Dense(1)(x3)\n",
    "    x3 = Activation('sigmoid')(x3)\n",
    "\n",
    "    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n",
    "    return stage2_dis\n",
    "\n",
    "def adv_model(gen_model2, dis_model, gen_model1):\n",
    "    embeddings_input_layer = Input(shape=(1024, ))\n",
    "    noise_input_layer = Input(shape=(100, ))\n",
    "    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n",
    "\n",
    "    gen_model1.trainable = False\n",
    "    dis_model.trainable = False\n",
    "\n",
    "    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n",
    "    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n",
    "    valid = dis_model([hr_images, compressed_embedding_input_layer])\n",
    "    \n",
    "    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 100\n",
    "GENERATED_IMAGE_PATH = \"generated_images/\"\n",
    "G_WEIGHTS_SAVEPATH = \"generator.h5\"\n",
    "D_WEIGHTS_SAVEPATH = \"discriminator.h5\"\n",
    "\n",
    "r_loss = []\n",
    "f_loss = []\n",
    "d_loss = []\n",
    "\n",
    "def train():\n",
    "    x_train = load_images(\"./generate_images/64images.pickle\")\n",
    "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    embeddings = load_embedings(\"./generate_images/char-CNN-RNN-embeddings.pickle\")\n",
    "    embeddings_test = load_embedings(\"./flowers/test/char-CNN-RNN-embeddings.pickle\")\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    d_opt = Adam(lr=0.00015, beta_1=0.5, beta_2=0.999)\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_opt)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    generator = Generator()\n",
    "    g_opt = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "    combined_model = Combined_model(generator, discriminator)\n",
    "    combined_model.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "    #dcgan = Sequential([generator, discriminator])\n",
    "    #g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "    #dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "    \n",
    "    compressed_embed = Compressed_embed()\n",
    "    compressed_embed.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "    \n",
    "    if os.path.exists(G_WEIGHTS_SAVEPATH):\n",
    "        generator.load_weights(G_WEIGHTS_SAVEPATH)\n",
    "        \n",
    "    if os.path.exists(D_WEIGHTS_SAVEPATH):\n",
    "        discriminator.load_weights(D_WEIGHTS_SAVEPATH)\n",
    "    \n",
    "    num_batches = int(x_train.shape[0] / BATCH_SIZE)\n",
    "    print('Number of batches:', num_batches)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        for index in range(num_batches):\n",
    "            #noise = np.array([np.random.uniform(0,1,100) for _ in range(BATCH_SIZE)])\n",
    "            noise = np.random.randn(BATCH_SIZE, 100)\n",
    "            image_batch = x_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            embedding_batch = embeddings[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images, _ = generator.predict([embedding_batch, noise], verbose=0)\n",
    "            \n",
    "            if index % 100 == 0:\n",
    "                z_noise2 = np.random.normal(0, 1, size=(BATCH_SIZE, 100))\n",
    "                embedding_batch = embeddings_test[0:32]\n",
    "                fake_images, _ = generator.predict([embedding_batch, z_noise2])\n",
    "                fake_images = fake_images*125.7 + 127.5\n",
    "                # Save image\n",
    "                Image.fromarray(np.uint8(fake_images[0])).save(\"./generate_images/images4/%depoch_%d.jpg\"%(epoch, index))\n",
    "            \n",
    "            compressed_embeddings = compressed_embed.predict_on_batch(embedding_batch)\n",
    "            compressed_embeddings = np.reshape(compressed_embeddings, (-1, 1, 1, 128))\n",
    "            compressed_embeddings = np.tile(compressed_embeddings, (1, 4, 4, 1))\n",
    "            \n",
    "#             X = np.concatenate((image_batch, generated_images))\n",
    "#             comp_emb = np.concatenate((compressed_embeddings, compressed_embeddings))\n",
    "            real_label = np.ones((BATCH_SIZE, 1)) * 0.9\n",
    "            fake_label = np.ones((BATCH_SIZE, 1)) * 0.1\n",
    "            real_d_loss = discriminator.train_on_batch([image_batch, compressed_embeddings], np.reshape(real_label, (BATCH_SIZE, 1)))\n",
    "            fake_d_loss = discriminator.train_on_batch([generated_images, compressed_embeddings],np.reshape(fake_label, (BATCH_SIZE, 1)))\n",
    "            \n",
    "            r_loss.append(real_d_loss)\n",
    "            f_loss.append(fake_d_loss)\n",
    "            d_loss.append(real_d_loss + fake_d_loss)\n",
    "            \n",
    "            #noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            noise = np.random.randn(BATCH_SIZE, 100)\n",
    "            g_loss = combined_model.train_on_batch([embedding_batch, noise, compressed_embeddings], [np.ones((BATCH_SIZE,1)) * 0.9, np.ones((BATCH_SIZE,256)) * 0.9])\n",
    "            #g_loss = dcgan.train_on_batch([embedding_batch, noise] ,[1]*BATCH_SIZE)\n",
    "        #print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" %(epoch, index, g_loss, d_loss))\n",
    "            print(\"epoch: %d, batch: %d\" %(epoch, index))\n",
    "\n",
    "        generator.save_weights(\"1023\"+G_WEIGHTS_SAVEPATH)\n",
    "        discriminator.save_weights(\"1023\"+D_WEIGHTS_SAVEPATH)\n",
    "\n",
    "#         generator.save_weights(G_WEIGHTS_SAVEPATH)\n",
    "#         discriminator.save_weights(D_WEIGHTS_SAVEPATH)\n",
    "#         plt.plot(range(NUM_EPOCH), r_loss, label=\"real_loss\")\n",
    "#         plt.plot(range(NUM_EPOCH), f_loss, label=\"fake_loss\")\n",
    "#         plt.plot(range(NUM_EPOCH), d_loss, label=\"comb_loss\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =2\n",
    "NUM_EPOCH = 2\n",
    "GENERATED_IMAGE_PATH = \"generated_images/\"\n",
    "G_WEIGHTS_SAVEPATH = \"generator.h5\"\n",
    "D_WEIGHTS_SAVEPATH = \"discriminator.h5\"\n",
    "\n",
    "def train2():\n",
    "    x_train = load_images(\"./generate_images/256images.pickle\")\n",
    "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    embeddings = load_embedings(\"./generate_images/char-CNN-RNN-embeddings.pickle\")\n",
    "    embeddings_test = load_embedings(\"./flowers/test/char-CNN-RNN-embeddings.pickle\")\n",
    "    \n",
    "    discriminator2 = Discriminator2()\n",
    "    d_opt = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "    discriminator2.compile(loss=\"binary_crossentropy\", optimizer=d_opt)\n",
    "    \n",
    "    generator = Generator()\n",
    "    g_opt = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=g_opt)\n",
    "    \n",
    "    generator.load_weights(G_WEIGHTS_SAVEPATH)\n",
    "    \n",
    "    generator2 = Generator2()\n",
    "    g_opt = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "    generator2.compile(loss=\"binary_crossentropy\", optimizer=g_opt)\n",
    "    \n",
    "    compressed_embed = Compressed_embed()\n",
    "    compressed_embed.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "    \n",
    "    \n",
    "    combined_model = adv_model(generator2, discriminator2,generator)\n",
    "    combined_model.compile(loss=['binary_crossentropy',KL_loss], loss_weights=[1.0, 2.0], optimizer=g_opt,metrics=None)\n",
    "\n",
    "    real_label = np.ones((BATCH_SIZE, 1)) * 0.9\n",
    "    fake_label = np.ones((BATCH_SIZE, 1)) * 0.1\n",
    "    \n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        gen_loss=[]\n",
    "        dis_loss=[]\n",
    "        \n",
    "        num_batches = int(x_train.shape[0] / BATCH_SIZE)\n",
    "        for index in range(num_batches):\n",
    "            #noise = np.array([np.random.uniform(0,1,100) for _ in range(BATCH_SIZE)])\n",
    "            noise = np.random.randn(BATCH_SIZE, 100)\n",
    "            image_batch = x_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            embedding_batch = embeddings[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            \n",
    "            in_fake_images, _ = generator.predict([embedding_batch, noise], verbose=3)\n",
    "            out_fake_images, _ = generator2.predict([embedding_batch, in_fake_images], verbose=3)\n",
    "            \n",
    "#             if index % 100 == 0:\n",
    "#                 z_noise2 = np.random.normal(0, 1, size=(BATCH_SIZE, 100))\n",
    "#                 embedding_batch = embeddings_test[0:32]\n",
    "#                 fake_images, _ = generator.predict([embedding_batch, z_noise2])\n",
    "#                 fake_images = fake_images*125.7 + 127.5\n",
    "#                 # Save image\n",
    "#                 Image.fromarray(np.uint8(fake_images[0])).save(\"./generate_images/images4/%depoch_%d.jpg\"%(epoch, index))\n",
    "            \n",
    "            compressed_embeddings = compressed_embed.predict_on_batch(embedding_batch)\n",
    "            compressed_embeddings = np.reshape(compressed_embeddings, (-1, 1, 1, 128))\n",
    "            compressed_embeddings = np.tile(compressed_embeddings, (1, 4, 4, 1))\n",
    "            \n",
    "\n",
    "            real_d_loss = discriminator2.train_on_batch([image_batch, compressed_embeddings], np.reshape(real_label, (BATCH_SIZE, 1)))\n",
    "            fake_d_loss = discriminator2.train_on_batch([out_fake_images, compressed_embeddings],np.reshape(fake_label, (BATCH_SIZE, 1)))\n",
    "            wrong_d_loss = discriminator2.train_on_batch([image_batch[:(BATCH_SIZE - 1)], compressed_embeddings[1:]],np.reshape(fake_label[1:], (BATCH_SIZE-1, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(real_d_loss, 0.5 * np.add(wrong_d_loss, fake_d_loss))\n",
    "                                  \n",
    "            \n",
    "            #g_loss = combined_model.train_on_batch([embedding_batch, noise, compressed_embeddings],[np.ones((BATCH_SIZE, 1)) * 0.9, np.ones((BATCH_SIZE, 256)) * 0.9])\n",
    "            g_loss = combined_model.train_on_batch([embedding_batch, noise, compressed_embeddings],[np.ones((BATCH_SIZE, 1)) * 0.9, np.ones((BATCH_SIZE, 256)) * 0.9])\n",
    "            print(\"g_loss:{}\".format(g_loss))\n",
    "            \n",
    "            dis_loss.append(d_loss)\n",
    "            gen_loss.append(g_loss)\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            #noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            noise = np.random.randn(BATCH_SIZE, 100)\n",
    "            embedding_batch = embeddings_test[0:32]\n",
    "            \n",
    "            in_fake_images, _ = generator.predict([embedding_batch, noise], verbose=3)\n",
    "            out_fake_images, _ = generator2.predict([embedding_batch, in_fake_images], verbose=3)\n",
    "            \n",
    "            for i, img in enumerate(out_fake_images[:10]):\n",
    "                Image.fromarray(np.uint8(img[0])).save(\"./generate_images/stage2/%depoch_%d.jpg\"%(epoch, i))\n",
    "            \n",
    "    generator2.save_weights(\"stage2_gen.h5\")\n",
    "    discriminator2.save_weights(\"stage2_dis.h5\")\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 3517\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-69ff44f0d652>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mz_noise2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0membedding_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0mfake_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_noise2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfake_images\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m125.7\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m127.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;31m# Save image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m       return training_arrays.predict_loop(\n\u001b[1;32m-> 1766\u001b[1;33m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1768\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    503\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    503\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "jpg/image_04948\n",
      "(1155, 10, 1024)\n"
     ]
    }
   ],
   "source": [
    "with open(\"../stackGAN-pre/Data/flowers/test/filenames.pickle\", \"rb\") as f:\n",
    "    filenames = pickle.load(f)\n",
    "\n",
    "with open(\"../stackGAN-pre/Data/flowers/test/class_info.pickle\", \"rb\") as f:\n",
    "    cl= pickle.load(f)\n",
    "\n",
    "with open(\"../stackGAN-pre/Data/flowers/test/char-CNN-RNN-embeddings.pickle\",\"rb\") as f:\n",
    "        embeddings_test = pickle.load(f,encoding=\"latin\")\n",
    "\n",
    "embeddings = np.array(embeddings_test)\n",
    "# with open(\"example-skipthoughts.pickle\",\"rb\") as f:\n",
    "#     embeddings_train = pickle.load(f,encoding=\"latin\")\n",
    "          \n",
    "# embeddings = np.array(embeddings_train)\n",
    "# print(embeddings.shape)\n",
    "#embeddings.reshape(1,5,-1)\n",
    "# embeddings_train = np.array(embeddings_train)\n",
    "\n",
    "with open(\"../stackGAN-pre/Data/flowers/test/304images.pickle\", \"rb\") as f:\n",
    "    images = pickle.load(f)\n",
    "    \n",
    "\n",
    "g = Generator()\n",
    "g.load_weights(\"generator.h5\")\n",
    "num = 60\n",
    "print(cl[60])\n",
    "print(filenames[60])\n",
    "# for i in range(5):\n",
    "#     z_noise2 = np.random.normal(0, 1, size=(32, 100))\n",
    "#     fake_images, _ = g.predict([embeddings[i], z_noise2])\n",
    "#     fake_images = fake_images*125.7 + 127.5\n",
    "#     Image.fromarray(np.uint8(fake_images[5])).save(\"./confirm/skipthouts/num%d.jpg\"%(i))      \n",
    "\n",
    "# z_noise2 = np.random.normal(0, 1, size=(32, 100))\n",
    "# fake_images, _ = g.predict([embeddings[0:32,0], z_noise2])\n",
    "# print(fake_images.shape)\n",
    "print(embeddings.shape)\n",
    "for i in range(32):\n",
    "    z_noise2 = np.random.normal(0, 1, size=(32, 100))\n",
    "    fake_images, _ = g.predict([embeddings[0:32,0], z_noise2])\n",
    "    fake_images = fake_images*125.7 + 127.5\n",
    "    Image.fromarray(np.uint8(fake_images[i])).save(\"./generate_images/confirm/t/num%d.jpg\"%(i))\n",
    "# embedding_batch = embeddings[0:1]\n",
    "# for i in range(10):\n",
    "# # # Save image\n",
    "#     for j in range(embeddings.shape[0]):\n",
    "#         if not os.path.exists(str(i)):\n",
    "#             os.mkdir(str(i))\n",
    "#             Image.fromarray(np.uint8(fake_images[i,j])).save(\"./%d/num%d_%d.jpg\"%(i,i,j))\n",
    "#Image.fromarray(np.uint8(fake_images[1])).save(\"result3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64be4d09cf03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"flowers/test/filenames.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"flowers/test/filenames.pickle\", \"rb\") as f:\n",
    "    filenames = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(\"flowers/test/char-CNN-RNN-embeddings.pickle\",\"rb\") as f:\n",
    "    emb = pickle.load(f,encoding=\"latin\")\n",
    "        \n",
    "    emb = np.array(emb)\n",
    "\n",
    "compressed_embed = Compressed_embed()\n",
    "compressed_embed.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "compressed_embedding = compressed_embed.predict(emb[448])\n",
    "compressed_embedding = compressed_embedding.reshape((1,10,128))\n",
    "compressed_embeddings = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "compressed_embeddings = np.tile(compressed_embeddings, (1, 4, 4, 1))\n",
    "\n",
    "real_img = np.array(Image.open(\"D:/Workspace/DeepLearning/GAN/stackGAN-pre/Data/flowers/jpg/image_06149.jpg\").resize((64,64))).reshape(1,64,64,3)\n",
    "\n",
    "fake_img = np.array(Image.open(\"D:/Workspace/DeepLearning/GAN/StackGAN/generate_images/confirm/cl19/num1.jpg\")).reshape(1,64,64,3)\n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator.load_weights(\"discriminator.h5\")\n",
    "\n",
    "# result = discriminator.predict([fake_img, compressed_embeddings])\n",
    "# print(result)\n",
    "plt.imshow(fake_img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e6062f2d5caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFrechetInceptionDistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgan_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_noise2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgan_fid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Workspace\\DeepLearning\\GAN\\StackGAN\\fid.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, real_images, generator_inputs, batch_size, num_batches_real, num_batches_gen, shuffle, seed)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \t\t(real_mean, real_cov) = self._stats(real_images,\n\u001b[1;32m--> 202\u001b[1;33m                         \u001b[1;34m\"real\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_batches_real\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \t\t\tshuffle=shuffle, seed=seed)\n\u001b[0;32m    204\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnum_batches_gen\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Workspace\\DeepLearning\\GAN\\StackGAN\\fid.py\u001b[0m in \u001b[0;36m_stats\u001b[1;34m(self, inputs, input_type, postprocessing, batch_size, num_batches, shuffle, seed)\u001b[0m\n\u001b[0;32m    178\u001b[0m                                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m                         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                         \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inception_v3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Workspace\\DeepLearning\\GAN\\StackGAN\\fid.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_range\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                         \u001b[0mimages\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind''"
     ]
    }
   ],
   "source": [
    "import fid\n",
    "generator = Generator()\n",
    "z_noise2 = np.random.normal(0, 1, size=(32, 100))\n",
    "\n",
    "with open(\"./Data/traning/64images.pickle\", \"rb\") as f:\n",
    "    images = pickle.load(f)\n",
    "\n",
    "fd = fid.FrechetInceptionDistance(generator, (0,1)) \n",
    "gan_fid = fd(images, z_noise2)\n",
    "print(gan_fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
